seed: 1919
save: "./checkpoint/cifar10-lru"
dataset:
  name: "CIFAR-10"
  _name_: "cifar"
  grayscale: True
train:
  num_epochs: 50
  batch_size: 50
  lr: 0.005
  ssm_lr:  0.001 # lr * lr_factor
  lr_min: 0.0000001
  reduce_factor: 0.5
  lr_patience: 20
  wd: 0.05
  warmup: 5
  cosine_anneal: True
model:
  layer: "lru"
  r_min: 0.9
  r_max: 0.99
  dt_min: 0.001
  dt_max: 0.1
  num_layers: 6
  activation: "full_glu"
  input_dim: 1
  output_dim: 10
  hidden_dim: 512 #x -> N
  state_dim: 64 #64 #u -> H
  dropout: 0.1
  norm: "batch"
  pooling: "mean"
  ssm_lr_vars: ["Lambda_re", "Lambda_im", "P", "B", "log_step"]
  prenorm: False
  dual: False
  
